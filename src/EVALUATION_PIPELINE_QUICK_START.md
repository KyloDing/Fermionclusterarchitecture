# 模型评测与 Pipeline 编排 - 快速开始指南

## 🚀 5分钟快速上手

本指南帮助您快速了解和使用模型评测与 Pipeline 编排功能。

---

## 📋 目录

1. [模型评测快速开始](#模型评测快速开始)
2. [Pipeline 编排快速开始](#pipeline-编排快速开始)
3. [常见使用场景](#常见使用场景)
4. [故障排查](#故障排查)

---

## 🎯 模型评测快速开始

### 步骤 1: 访问评测页面

```
导航路径: 数据资产 → 模型评测
URL: /model-evaluation
```

### 步骤 2: 查看评测任务

**页面布局**：
```
┌─────────────────────────────────────┐
│  模型评测              [新建评测]    │
├─────────────────────────────────────┤
│  📊 统计卡片                         │
│  [总任务] [运行中] [已完成] [失败]  │
├─────────────────────────────────────┤
│  Tab导航                             │
│  [评测任务] [评测模板] [排行榜]      │
├─────────────────────────────────────┤
│  🔍 搜索和筛选                       │
├─────────────────────────────────────┤
│  📋 任务列表                         │
│  - Qwen2-7B 综合评测 ✅ 已完成      │
│  - GLM-4 vs Qwen2 对比 🔄 运行中    │
│  - Llama-3-8B 安全性 ⏳ 等待中      │
└─────────────────────────────────────┘
```

### 步骤 3: 创建评测任务（开发中）

点击 **"新建评测"** 按钮（功能开发中，当前查看示例数据）

**示例任务**：

#### 任务 1: Qwen2-7B 综合评测
```yaml
名称: Qwen2-7B 综合评测
类型: 基准评测
模型: Qwen2-7B-Instruct v1.0
状态: ✅ 已完成

数据集:
  - MMLU (英文多任务理解)
  - C-Eval (中文综合能力)
  - HumanEval (Python代码生成)

评测指标:
  - 准确率: 78.5%
  - 推理延迟: 45ms
  - 吞吐量: 120 req/s

综合评分: 82.3

资源配置:
  - GPU: 1x NVIDIA A100
  - 内存: 40GB
  - 耗时: 2.5小时
```

#### 任务 2: GLM-4 vs Qwen2 对比评测
```yaml
名称: GLM-4 vs Qwen2 对比评测
类型: 对比评测
主模型: GLM-4-9B v1.0
对比模型: Qwen2-7B v1.0
状态: 🔄 运行中 (65%)

数据集:
  - C-Eval (中文综合能力)
  - GSM8K (数学推理)

评测指标:
  - 准确率
  - 困惑度

资源配置:
  - GPU: 2x NVIDIA A100
  - 内存: 80GB
```

### 步骤 4: 查看评测结果

点击任务可查看详细结果（开发中）

**结果示例**：
```
📊 Qwen2-7B 综合评测结果

整体表现: ⭐⭐⭐⭐☆ (82.3/100)

性能指标:
┌────────────────┬─────────┬──────┐
│ 指标           │ 数值    │ 等级 │
├────────────────┼─────────┼──────┤
│ 准确率         │ 78.5%   │ 优秀 │
│ 推理延迟       │ 45ms    │ 良好 │
│ 吞吐量         │ 120/s   │ 优秀 │
└────────────────┴─────────┴──────┘

数据集分项:
• MMLU: 76.2% 准确率
• C-Eval: 81.5% 准确率
• HumanEval: 77.8% pass@1

💡 建议:
- 代码生成能力良好，可用于编程辅助
- 中文能力优于英文，适合中文场景
- 推理速度快，适合实时应用
```

### 步骤 5: 操作功能

**任务操作菜单**：
- 👁️ **查看详情** - 查看完整评测报告
- ⏸️ **取消任务** - 取消运行中的任务
- 📥 **下载报告** - 下载PDF评测报告
- 🗑️ **删除** - 删除评测任务

---

## 🔄 Pipeline 编排快速开始

### 步骤 1: 访问 Pipeline 页面

```
导航路径: 数据资产 → Pipeline编排
URL: /pipeline-orchestration
```

### 步骤 2: 查看流水线列表

**页面布局**：
```
┌─────────────────────────────────────┐
│  Pipeline 编排    [模板] [新建]     │
├─────────────────────────────────────┤
│  📊 统计卡片                         │
│  [总数] [运行中] [已完成] [失败]    │
├─────────────────────────────────────┤
│  Tab导航                             │
│  [流水线] [运行历史] [模板库]        │
├─────────────────────────────────────┤
│  🔍 搜索和筛选                       │
├─────────────────────────────────────┤
│  📋 流水线列表                       │
│  - Qwen2-7B 微调流水线 ✅ 已完成    │
│  - 图像分类模型训练 🔄 运行中        │
└─────────────────────────────────────┘
```

### 步骤 3: 查看示例 Pipeline

#### Pipeline 1: Qwen2-7B 微调流水线

**基本信息**：
```yaml
名称: Qwen2-7B 微调流水线
版本: v1.2.0
类别: 模型训练
状态: ✅ 已完成
```

**流程步骤**：
```
1️⃣ 数据预处理 ──→ 2️⃣ 数据增强 ──→ 3️⃣ 模型训练 ──→ 4️⃣ 模型评测 ──→ 5️⃣ 模型部署
   (15分钟)        (15分钟)        (3小时)        (30分钟)       (10分钟)
```

**详细配置**：

**步骤 1: 数据预处理**
```yaml
类型: 📊 数据预处理
容器: registry.fermilab.com/data-processor:v1.0
命令: python preprocess.py
资源:
  CPU: 8核
  内存: 32GB
输入:
  - 原始数据集: dataset-raw-001
输出:
  - 处理后数据: /output/processed
状态: ✅ 已完成
耗时: 15分钟
```

**步骤 2: 数据增强**
```yaml
类型: 🔄 数据增强
容器: registry.fermilab.com/data-augmentor:v1.0
资源:
  CPU: 4核
  内存: 16GB
依赖: 步骤1
状态: ✅ 已完成
耗时: 15分钟
```

**步骤 3: 模型训练**
```yaml
类型: 🎯 模型训练
容器: registry.fermilab.com/llm-trainer:v2.0
命令: python train.py --model=qwen2-7b --method=lora --epochs=3
资源:
  CPU: 16核
  内存: 64GB
  GPU: 4x NVIDIA A100
依赖: 步骤2
输出:
  - 训练后模型: /output/model
  - 训练指标: /output/metrics.json
状态: ✅ 已完成
耗时: 3小时
```

**步骤 4: 模型评测**
```yaml
类型: 📈 模型评测
容器: registry.fermilab.com/model-evaluator:v1.0
资源:
  CPU: 8核
  内存: 32GB
  GPU: 1x NVIDIA A100
依赖: 步骤3
状态: ✅ 已完成
耗时: 30分钟
```

**步骤 5: 模型部署**
```yaml
类型: 🚀 模型部署
容器: registry.fermilab.com/model-deployer:v1.0
资源:
  CPU: 4核
  内存: 16GB
依赖: 步骤4
状态: ✅ 已完成
耗时: 10分钟
```

**运行统计**：
```
总运行次数: 12次
成功: 10次 (83.3%)
失败: 2次
最后运行: 2024-11-14
总耗时: 4小时10分钟
```

### 步骤 4: 查看运行历史

切换到 **"运行历史"** Tab

**运行记录示例**：
```
┌──────────┬────────────────┬────────┬────────┬──────────┬──────┬────────┐
│ 运行ID   │ 流水线         │ 触发   │ 状态   │ 开始时间 │ 耗时 │ 成本   │
├──────────┼────────────────┼────────┼────────┼──────────┼──────┼────────┤
│ run-001  │ Qwen2-7B微调   │ 手动   │ ✅完成 │ 11-14    │ 4.2h │ ¥128.50│
│          │ v1.2.0         │ 张三   │        │ 08:00    │      │        │
└──────────┴────────────────┴────────┴────────┴──────────┴──────┴────────┘

资源使用:
• CPU时间: 48核时
• 内存时间: 256GB时
• GPU时间: 12卡时

输出:
• 模型: qwen2-7b-finetuned-v1
• 指标: accuracy=0.92, loss=0.15
```

### 步骤 5: 使用模板创建 Pipeline

切换到 **"模板库"** Tab

**可用模板**：

#### 模板 1: 🤖 大语言模型微调
```yaml
描述: 通用的大语言模型微调流水线模板，支持 LoRA、QLoRA 等方法
评分: ⭐⭐⭐⭐⭐ 4.8
使用量: 245次
类别: 模型训练

流程:
1. 数据预处理
2. 模型训练
3. 模型评测

参数:
• 基座模型: [Qwen2-7B | Llama-3-8B | GLM-4-9B]
• 训练数据集: [选择数据集]
• 学习率: 0.0001
```

**使用步骤**：
1. 点击模板的 **"使用模板"** 按钮
2. 填写参数（开发中）
3. 自动生成 Pipeline
4. 运行流水线

#### 模板 2: 🖼️ 计算机视觉模型训练
```yaml
描述: 图像分类、目标检测等CV模型的训练流水线
评分: ⭐⭐⭐⭐ 4.5
使用量: 123次
类别: 模型训练
```

### 步骤 6: 操作功能

**Pipeline 操作菜单**：
- ▶️ **运行** - 启动流水线执行
- 👁️ **查看详情** - 查看步骤和配置
- 📋 **复制** - 复制为新流水线
- 📥 **导出** - 导出 YAML 配置
- 🗑️ **删除** - 删除流水线

---

## 💡 常见使用场景

### 场景 1: 评测新训练的模型

**目标**: 评估刚训练完成的模型性能

**步骤**:
```
1. 训练完成后，进入模型评测页面
2. 点击"新建评测"
3. 选择刚训练的模型
4. 选择合适的评测数据集（如 MMLU、C-Eval）
5. 选择评测指标（准确率、延迟等）
6. 配置GPU资源（建议1-2张A100）
7. 提交运行
8. 等待完成后查看结果
9. 下载评测报告
```

**预期时间**: 30分钟 - 2小时（取决于数据集大小）

### 场景 2: 对比两个模型

**目标**: 比较不同模型在相同任务上的表现

**步骤**:
```
1. 创建对比评测任务
2. 选择主模型
3. 添加对比模型
4. 选择相同的数据集和指标
5. 运行评测
6. 查看并排对比结果
```

**提示**: 
- 使用相同配置保证公平对比
- 选择有代表性的数据集
- 关注多个维度的指标

### 场景 3: 端到端模型开发

**目标**: 从数据处理到模型部署的完整流程

**步骤**:
```
1. 进入 Pipeline 编排页面
2. 选择"大语言模型微调"模板
3. 配置参数:
   - 基座模型: Qwen2-7B
   - 数据集: 您的训练数据
   - 学习率: 0.0001
4. 创建 Pipeline
5. 运行流水线
6. 监控各步骤进度
7. 查看最终输出
```

**优势**:
- 自动化执行，无需人工干预
- 步骤依赖自动处理
- 完整的执行记录
- 资源和成本统计

### 场景 4: 定期重训练

**目标**: 每周自动重新训练模型

**步骤**:
```
1. 创建训练 Pipeline
2. 配置调度:
   Cron: 0 2 * * 1  # 每周一凌晨2点
   时区: Asia/Shanghai
3. 配置通知:
   邮件: team@company.com
4. 启用调度
5. 系统自动执行
```

**好处**:
- 模型持续更新
- 无需手动触发
- 自动通知结果

---

## 🔧 故障排查

### 问题 1: 评测任务一直等待

**可能原因**:
- GPU 资源不足
- 队列中有其他任务

**解决方案**:
```
1. 检查计算节点状态
2. 查看GPU资源使用情况
3. 等待前序任务完成
4. 或调整资源配置
```

### 问题 2: Pipeline 步骤失败

**排查步骤**:
```
1. 查看失败步骤的错误日志
2. 检查资源配置是否充足
3. 验证输入数据是否正确
4. 检查容器镜像是否可用
5. 尝试单独运行失败步骤
```

**常见错误**:
- OOM (内存不足): 增加内存配置
- Timeout (超时): 增加超时时间
- Image Pull Error: 检查镜像地址

### 问题 3: 评测结果异常

**检查项**:
```
1. 数据集是否正确
2. 模型版本是否匹配
3. 评测参数是否合理
4. GPU资源是否稳定
```

### 问题 4: Pipeline 无法运行

**可能原因**:
- 步骤配置不完整
- 依赖关系错误
- 资源配额不足

**解决方案**:
```
1. 检查每个步骤的配置
2. 验证依赖关系（不能有循环）
3. 确认有足够的资源配额
4. 查看详细错误信息
```

---

## 📚 下一步

### 深入学习

1. **阅读完整文档**
   - [模型评测与Pipeline编排完整文档](./MODEL_EVALUATION_AND_PIPELINE.md)

2. **了解评测基准**
   - MMLU 评测标准
   - C-Eval 评测方法
   - HumanEval 代码评估

3. **学习 Pipeline 设计**
   - Kubeflow Pipelines 概念
   - 步骤依赖管理
   - 资源优化策略

### 实践练习

1. **创建第一个评测任务**（开发中）
   - 选择简单的数据集
   - 使用默认配置
   - 观察执行过程

2. **使用模板创建 Pipeline**（开发中）
   - 从内置模板开始
   - 修改参数
   - 运行并观察结果

3. **设计自定义流程**（开发中）
   - 理解业务需求
   - 拆分执行步骤
   - 配置依赖关系

---

## 🎯 核心要点总结

### 模型评测

✅ **三种评测类型**: 基准、自定义、对比  
✅ **丰富的指标**: 质量、性能、安全、效率  
✅ **标准数据集**: MMLU、C-Eval、HumanEval等  
✅ **详细报告**: 可视化结果、下载PDF  

### Pipeline 编排

✅ **端到端流程**: 数据→训练→评测→部署  
✅ **可视化管理**: 直观的步骤展示  
✅ **自动化执行**: 依赖管理、资源调度  
✅ **模板复用**: 快速创建标准流程  

### 推荐工作流

```
1. 准备数据集
   ↓
2. 使用 Pipeline 训练模型
   ↓
3. 使用评测模块测试性能
   ↓
4. 根据结果优化
   ↓
5. 部署到生产环境
```

---

## 🆘 获取帮助

**需要帮助？**

- 📧 邮件: support@fermilab.com
- 💬 企业微信: FermiCluster支持群
- 📖 文档: [完整文档](./MODEL_EVALUATION_AND_PIPELINE.md)
- 🐛 问题反馈: 系统内"问题反馈"功能

---

**文档版本**: v1.0  
**最后更新**: 2024-11-14  
**下次更新**: 功能完善后更新实际操作步骤
