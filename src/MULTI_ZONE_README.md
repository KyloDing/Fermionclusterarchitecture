# 跨可用区调度功能 🌐

> 费米集群系统跨可用区AI工作负载调度功能

## 🎯 功能概述

跨可用区调度功能允许您在多个可用区分配计算资源，实现高可用、高性能的分布式AI训练和推理服务。支持在A可用区2节点、B可用区3节点这样的灵活配置，启动分布式训练或推理任务。

### 核心特性

- ✅ **多可用区资源配置** - 灵活分配不同可用区的计算资源
- ✅ **实时拓扑可视化** - 直观展示资源分布和网络连接
- ✅ **智能调度策略** - 支持多种分布式训练策略
- ✅ **完整监控体系** - 多维度实时监控和日志查看
- ✅ **成本透明化** - 实时计算资源使用费用

## 📦 新增组件

### 1. 核心对话框组件
```
/components/dialogs/MultiZoneSchedulingDialog.tsx
```
- 支持训练和推理两种模式
- 可用区选择和资源配置
- 实时费用预估
- 分布式策略选择

### 2. 拓扑可视化组件
```
/components/MultiZoneTopologyView.tsx
```
- 可用区网络拓扑图
- 节点网格可视化
- 资源统计卡片
- 区域分组展示

### 3. 任务详情页面
```
/components/pages/MultiZoneTaskDetailPage.tsx
```
- 任务进度监控
- 资源使用监控
- 实时日志查看
- 任务控制功能

### 4. 页面集成

**训练任务页面** (`/components/pages/TrainingJobsPage.tsx`)
- 新增"跨可用区训练"按钮
- 集成跨可用区调度对话框

**推理服务页面** (`/components/pages/InferenceServicesPage.tsx`)
- 新增"跨可用区部署"按钮
- 支持全球化推理部署

## 🚀 快速开始

### 方法1：使用界面操作

1. **打开训练任务页面**
   ```
   导航 → 训练任务 → 点击"跨可用区训练"按钮
   ```

2. **配置任务信息**
   ```
   任务名称：GPT大模型分布式训练
   框架：PyTorch
   分布式策略：数据并行（DDP）
   ```

3. **添加可用区A**
   ```
   选择：A可用区（北京-1）
   节点：2台
   GPU：8张/节点
   → 小计：16 GPU
   ```

4. **添加可用区B**
   ```
   选择：B可用区（北京-2）
   节点：3台
   GPU：8张/节点
   → 小计：24 GPU
   ```

5. **启动任务**
   ```
   总资源：5节点，40 GPU
   预计费用：¥348.00/小时
   → 点击"启动分布式训练"
   ```

### 方法2：使用配置模板

#### 小规模测试（8 GPU）
```typescript
{
  taskName: "模型验证测试",
  framework: "pytorch",
  distributionStrategy: "ddp",
  zones: [
    {
      zoneId: "zone-a",
      nodeCount: 1,
      gpuPerNode: 8
    }
  ]
}
```

#### 中等规模训练（16 GPU）
```typescript
{
  taskName: "BERT中文预训练",
  framework: "pytorch",
  distributionStrategy: "ddp",
  zones: [
    {
      zoneId: "zone-a",
      nodeCount: 2,
      gpuPerNode: 4
    },
    {
      zoneId: "zone-b",
      nodeCount: 2,
      gpuPerNode: 4
    }
  ]
}
```

#### 大规模训练（64 GPU）
```typescript
{
  taskName: "GPT-3模型训练",
  framework: "pytorch",
  distributionStrategy: "hybrid",
  zones: [
    {
      zoneId: "zone-a",
      nodeCount: 4,
      gpuPerNode: 8
    },
    {
      zoneId: "zone-b",
      nodeCount: 4,
      gpuPerNode: 8
    }
  ]
}
```

## 📖 文档导航

### 📚 完整文档
- **[使用指南](./MULTI_ZONE_SCHEDULING_GUIDE.md)** - 详细的功能说明和最佳实践
- **[快速开始](./MULTI_ZONE_QUICK_START.md)** - 5分钟快速上手教程
- **[功能总结](./MULTI_ZONE_FEATURE_SUMMARY.md)** - 技术实现和设计文档

### 🎓 学习路径

**初学者**：
1. 阅读快速开始文档（5分钟）
2. 使用小规模配置测试（10分钟）
3. 查看任务监控和日志（5分钟）

**进阶用户**：
1. 阅读完整使用指南（20分钟）
2. 尝试不同的分布式策略（30分钟）
3. 优化成本和性能（持续）

**专家用户**：
1. 研究技术实现文档
2. 自定义配置模板
3. 参与社区贡献

## 🎨 界面预览

### 跨可用区调度对话框
```
┌─────────────────────────────────────────────┐
│ 🌐 跨可用区分布式训练                        │
├─────────────────────────────────────────────┤
│ 任务名称: [___________________________]     │
│ 框架: [PyTorch ▼]  策略: [数据并行 ▼]      │
│                                             │
│ 📍 选择可用区                               │
│ [A可用区（北京-1）▼] [+ 添加可用区]        │
│                                             │
│ 🖥️ 资源分配配置                            │
│ ┌─────────────────────────────────────┐   │
│ │ A  A可用区（北京-1）    [健康]       │   │
│ │ 节点: [-] 2 [+]                      │   │
│ │ GPU: [8 ▼] CPU: [64 ▼] 内存: [256▼] │   │
│ │ 小计: 2节点, 16 GPU                  │   │
│ └─────────────────────────────────────┘   │
│ ┌─────────────────────────────────────┐   │
│ │ B  B可用区（北京-2）    [健康]       │   │
│ │ 节点: [-] 3 [+]                      │   │
│ │ GPU: [8 ▼] CPU: [64 ▼] 内存: [256▼] │   │
│ │ 小计: 3节点, 24 GPU                  │   │
│ └─────────────────────────────────────┘   │
│                                             │
│ 📊 总资源统计                               │
│ ┌─────────────────────────────────────┐   │
│ │ 5节点 | 40 GPU | 320核 | 1280 GB    │   │
│ │ 预计费用: ¥348.00/小时              │   │
│ └─────────────────────────────────────┘   │
│                                             │
│         [取消]  [启动分布式训练]            │
└─────────────────────────────────────────────┘
```

### 跨可用区拓扑视图
```
┌─────────────────────────────────────────────┐
│ 🌐 跨可用区拓扑                              │
├─────────────────────────────────────────────┤
│ 📍 北京区域 ────────────────────────────   │
│                                             │
│ ┌──────────┐  ┌──────────┐                │
│ │ A 北京-1  │  │ B 北京-2  │                │
│ │ 1.2ms    │  │ 1.5ms    │                │
│ │ ▢▢▢▢     │  │ ▢▢▢▢     │                │
│ │ ▢▢▢▢     │  │ ▢▢▢▢     │                │
│ │ 16 GPU   │  │ ▢▢+1     │                │
│ └──────────┘  │ 24 GPU   │                │
│               └──────────┘                 │
│                                             │
│ 🌐 跨可用区网络                             │
│ ┌─────────────────────────────────────┐   │
│ │ A 北京-1 ⟷ B 北京-2                  │   │
│ │   1.3ms                              │   │
│ └─────────────────────────────────────┘   │
└─────────────────────────────────────────────┘
```

## 💡 使用场景

### 场景1：大规模分布式训练
**需求**：训练GPT-3等大模型，需要64张GPU

**配置**：
- A可用区：4节点 × 8GPU = 32 GPU
- B可用区：4节点 × 8GPU = 32 GPU
- 延迟：< 2ms
- 策略：混合并行

**优势**：
- ✅ 突破单可用区资源限制
- ✅ 低延迟保证训练效率
- ✅ 高可用保障任务不中断

### 场景2：全球化推理服务
**需求**：为全球用户提供在线翻译服务

**配置**：
- 北京可用区：8 GPU（服务华北）
- 上海可用区：8 GPU（服务华东）
- 深圳可用区：8 GPU（服务华南）

**优势**：
- ✅ 就近服务，降低用户延迟
- ✅ 负载均衡，资源利用充分
- ✅ 多地容灾，服务高可用

### 场景3：弹性资源调度
**需求**：根据负载动态调整资源

**配置**：
- 主可用区：常驻资源
- 备可用区：按需扩容

**优势**：
- ✅ 成本优化，按需付费
- ✅ 快速响应，自动扩缩容
- ✅ 灵活调度，适应业务变化

## 🔧 技术架构

### 前端组件架构
```
MultiZoneSchedulingDialog (主对话框)
├── 基本信息配置
│   ├── 任务名称/描述
│   ├── 框架选择
│   └── 分布式策略
├── 可用区管理
│   ├── 可用区选择
│   ├── 可用区列表
│   └── 资源配置
└── 资源统计
    ├── 总资源计算
    └── 费用预估

MultiZoneTopologyView (拓扑视图)
├── 区域分组
│   └── 可用区卡片
│       ├── 节点网格
│       ├── 资源统计
│       └── 状态展示
└── 网络拓扑
    └── 连接示意图

MultiZoneTaskDetailPage (任务详情)
├── 任务概览
├── 拓扑视图
├── 监控指标
└── 实时日志
```

### 数据流
```
用户操作
  ↓
状态更新 (useState)
  ↓
实时计算 (总资源/费用)
  ↓
界面渲染 (React组件)
  ↓
提交配置 (onConfirm回调)
  ↓
创建任务 (API调用)
```

## 📊 性能指标

### 网络延迟
- 同区域可用区：< 2ms ✅ 推荐
- 跨区域可用区：5-20ms ⚠️ 谨慎使用

### 资源利用率
- GPU利用率目标：> 85%
- 内存使用合理范围：60-80%
- 网络带宽使用：< 90%

### 成本效率
- GPU费用：¥8.50/小时/张
- CPU费用：¥0.20/小时/核
- 跨区流量：按实际使用计费

## 🎯 最佳实践

### ✅ 推荐做法

1. **同区域多可用区**
   - 延迟低（< 2ms）
   - 效率高
   - 适合分布式训练

2. **资源均衡配置**
   - 各可用区配置一致
   - 避免负载不均
   - 提高训练效率

3. **实时监控**
   - 监控资源使用
   - 及时发现问题
   - 优化配置参数

4. **定期保存检查点**
   - 防止数据丢失
   - 支持断点续传
   - 快速故障恢复

### ❌ 避免事项

1. **过度跨区域**
   - 延迟高影响效率
   - 通信开销大
   - 成本增加

2. **资源配置不合理**
   - 过大浪费资源
   - 过小影响性能
   - 需根据实际调整

3. **忽视监控告警**
   - 问题发现不及时
   - 影响任务进度
   - 可能导致失败

## 🐛 故障排查

### 问题：跨可用区通信失败
**症状**：任务启动后网络连接异常

**排查**：
1. 检查安全组配置
2. 验证网络互通性
3. 查看防火墙规则

**解决**：
- 配置正确的安全组规则
- 确保可用区间网络互通

### 问题：训练速度慢
**症状**：训练吞吐量低于预期

**排查**：
1. 检查网络延迟
2. 查看GPU利用率
3. 分析日志信息

**解决**：
- 使用同区域可用区
- 开启梯度压缩
- 调整batch size

### 问题：资源分配不均
**症状**：某些节点利用率很高，其他很低

**排查**：
1. 检查各可用区配置
2. 查看负载分布
3. 分析调度策略

**解决**：
- 确保各可用区配置一致
- 调整分布式策略
- 重新分配资源

## 📞 获取帮助

### 文档资源
- 📖 [完整使用指南](./MULTI_ZONE_SCHEDULING_GUIDE.md)
- 🚀 [快速开始](./MULTI_ZONE_QUICK_START.md)
- 📊 [功能总结](./MULTI_ZONE_FEATURE_SUMMARY.md)

### 技术支持
- 📧 邮箱：support@fermi-cluster.com
- 📞 电话：400-xxx-xxxx
- 💬 在线客服：工作日 9:00-18:00
- 🌐 文档中心：https://docs.fermi-cluster.com

### 社区资源
- 💬 用户论坛：https://forum.fermi-cluster.com
- 📺 视频教程：https://videos.fermi-cluster.com
- 📝 博客文章：https://blog.fermi-cluster.com

## 🎉 开始使用

准备好了吗？立即开始您的跨可用区AI工作负载调度之旅！

1. 📖 阅读[快速开始文档](./MULTI_ZONE_QUICK_START.md)（5分钟）
2. 🚀 创建您的第一个跨可用区任务（10分钟）
3. 📊 查看监控和优化配置（持续）

**祝您使用愉快！** 🎊

---

**版本**：v1.0.0  
**发布日期**：2024-12-05  
**维护者**：费米集群开发团队
