# 跨可用区调度功能使用指南

## 功能概述

跨可用区调度功能允许您在多个可用区分配计算资源，实现高可用、高性能的分布式AI训练和推理服务。

## 核心优势

### 🌐 高可用性
- **容错能力**：资源分散在多个可用区，单点故障不影响整体任务
- **业务连续性**：某个可用区故障时，任务可继续在其他可用区运行
- **灾备机制**：自动故障转移，保障业务不中断

### ⚡ 性能优化
- **就近调度**：优先使用低延迟可用区，提升训练效率
- **负载均衡**：智能分配资源，避免单区过载
- **弹性扩展**：根据负载动态调整各可用区的资源分配

### 💰 成本优化
- **资源池化**：充分利用各可用区的空闲资源
- **峰谷调度**：根据不同可用区的价格策略选择最优配置
- **按需付费**：只为实际使用的资源付费

## 使用场景

### 1. 大规模分布式训练
- **场景**：GPT、BERT等大模型训练，需要数十甚至上百张GPU
- **配置示例**：
  - A可用区（北京-1）：4节点 × 8GPU = 32 GPU
  - B可用区（北京-2）：4节点 × 8GPU = 32 GPU
  - 总计：64 GPU，同区域延迟 < 2ms

### 2. 多区域推理服务
- **场景**：全球化应用，需要在多个地域提供低延迟推理服务
- **配置示例**：
  - A可用区（北京）：2节点 × 4GPU = 8 GPU
  - B可用区（上海）：2节点 × 4GPU = 8 GPU
  - C可用区（深圳）：2节点 × 4GPU = 8 GPU

### 3. 高可用生产环境
- **场景**：关键业务系统，要求99.99%可用性
- **配置示例**：
  - 主可用区：3节点 × 4GPU = 12 GPU（处理80%流量）
  - 备可用区：2节点 × 4GPU = 8 GPU（处理20%流量 + 故障转移）

## 快速开始

### 步骤1：访问跨可用区调度界面

#### 训练任务
1. 进入 **训练任务** 页面
2. 点击右上角 **跨可用区训练** 按钮
3. 打开跨可用区调度对话框

#### 推理服务
1. 进入 **推理服务** 页面
2. 点击右上角 **跨可用区部署** 按钮
3. 打开跨可用区调度对话框

### 步骤2：配置基本信息

填写任务基本信息：
- **任务名称**：例如 "GPT大模型分布式训练"
- **任务描述**：描述训练目标、数据集等
- **训练框架**：PyTorch / TensorFlow / PaddlePaddle / MXNet
- **分布式策略**：
  - 数据并行（DDP）- 适合中小模型
  - 全分片数据并行（FSDP）- 适合大模型
  - 流水线并行 - 适合超大模型
  - 张量并行 - 适合Transformer模型
  - 混合并行 - 结合多种策略

### 步骤3：选择可用区

系统提供多个可用区供选择：

| 可用区 | 区域 | 可用节点 | 延迟 | 状态 |
|--------|------|----------|------|------|
| A可用区（北京-1） | 北京 | 24节点 | 1.2ms | 健康 |
| B可用区（北京-2） | 北京 | 18节点 | 1.5ms | 健康 |
| C可用区（上海-1） | 上海 | 32节点 | 8.5ms | 健康 |
| D可用区（深圳-1） | 深圳 | 16节点 | 12.3ms | 降级 |

**选择建议**：
- ✅ **同区域优先**：延迟 < 2ms，适合分布式训练
- ⚠️ **跨区域谨慎**：延迟 5-20ms，通信开销较大
- ❌ **避免降级**：优先选择健康状态的可用区

### 步骤4：配置资源分配

为每个可用区配置资源：

#### A可用区配置
- **节点数量**：2 台（使用 +/- 按钮调整）
- **GPU/节点**：8 张（1/2/4/8可选）
- **CPU核心/节点**：64 核
- **内存/节点**：256 GB

#### B可用区配置
- **节点数量**：3 台
- **GPU/节点**：8 张
- **CPU核心/节点**：64 核
- **内存/节点**：256 GB

#### 资源汇总
- **总节点数**：5 台
- **GPU总数**：40 张（A区16张 + B区24张）
- **CPU总数**：320 核
- **内存总量**：1,280 GB
- **预计费用**：¥406.00/小时

### 步骤5：启动任务

检查配置无误后：
1. 点击 **启动分布式训练** 或 **部署推理服务**
2. 系统自动在各可用区分配资源
3. 建立跨可用区网络连接
4. 初始化分布式环境
5. 开始执行任务

## 配置示例

### 示例1：中等规模训练（16-32 GPU）

**场景**：BERT中文预训练，需要16张GPU

**配置**：
```
任务名称：BERT中文预训练
框架：PyTorch
分布式策略：数据并行（DDP）

可用区配置：
- A可用区（北京-1）
  - 节点：2台
  - GPU：8张/节点
  - CPU：64核/节点
  - 内存：256GB/节点
  - 小计：16 GPU

总资源：2节点，16 GPU
预计费用：¥142.80/小时
```

**适用性**：
- ✅ 单可用区资源充足
- ✅ 无跨区通信开销
- ✅ 延迟低，效率高

### 示例2：大规模训练（64+ GPU）

**场景**：GPT-3模型训练，需要64张GPU

**配置**：
```
任务名称：GPT-3大模型训练
框架：PyTorch
分布式策略：混合并行（DDP + Pipeline）

可用区配置：
- A可用区（北京-1）
  - 节点：4台
  - GPU：8张/节点
  - 小计：32 GPU
  
- B可用区（北京-2）
  - 节点：4台
  - GPU：8张/节点
  - 小计：32 GPU

总资源：8节点，64 GPU
预计费用：¥595.20/小时
```

**优势**：
- ✅ 资源充足，满足大规模训练需求
- ✅ 同区域延迟低（< 2ms）
- ✅ 高可用，单区故障不影响训练

### 示例3：全球化推理服务

**场景**：在线翻译服务，需要在多地域部署

**配置**：
```
任务名称：全球翻译推理服务
框架：PyTorch
分布式策略：数据并行（DDP）

可用区配置：
- A可用区（北京）
  - 节点：2台
  - GPU：4张/节点
  - 小计：8 GPU（服务华北地区）
  
- B可用区（上海）
  - 节点：2台
  - GPU：4张/节点
  - 小计：8 GPU（服务华东地区）
  
- C可用区（深圳）
  - 节点：2台
  - GPU：4张/节点
  - 小计：8 GPU（服务华南地区）

总资源：6节点，24 GPU
预计费用：¥219.20/小时
```

**优势**：
- ✅ 就近服务，降低用户延迟
- ✅ 多地容灾，高可用性
- ✅ 负载均衡，资源利用充分

## 网络延迟参考

### 同区域可用区（推荐用于分布式训练）
- **A可用区 ↔ B可用区**：1.3ms
- **通信效率**：极高
- **适用场景**：分布式训练、实时推理

### 跨区域可用区（谨慎使用）
- **北京 ↔ 上海**：8.5ms
- **北京 ↔ 深圳**：12.3ms
- **上海 ↔ 深圳**：9.8ms
- **通信效率**：较低
- **适用场景**：推理服务、异步训练

## 分布式策略选择

### 数据并行（DDP）
**适用**：中小模型（< 10B参数）
**特点**：
- 每个GPU维护完整模型副本
- 并行处理不同数据
- 通信梯度数据
**网络要求**：中等（梯度同步）

### 全分片数据并行（FSDP）
**适用**：大模型（10B-100B参数）
**特点**：
- 模型参数分片到各GPU
- 节省显存
- 支持更大模型
**网络要求**：高（频繁通信）

### 流水线并行
**适用**：超大模型（100B+参数）
**特点**：
- 模型按层切分
- GPU之间流水线传递
- 减少通信量
**网络要求**：低（层间通信）

### 混合并行
**适用**：超大规模训练
**特点**：
- 结合多种策略
- 最大化资源利用
- 需要精细调优
**网络要求**：根据组合策略而定

## 监控与优化

### 实时监控指标
- **GPU利用率**：目标 > 85%
- **内存使用**：避免OOM
- **网络带宽**：跨区通信监控
- **训练吞吐**：samples/s

### 性能优化建议
1. **梯度压缩**：减少跨区通信数据量
2. **混合精度训练**：FP16/BF16加速
3. **梯度累积**：减少同步频率
4. **异步通信**：重叠计算与通信

### 故障处理
- **自动重试**：节点故障自动恢复
- **断点续传**：保存检查点，支持恢复
- **故障转移**：自动切换到备用可用区

## 成本优化

### 费用组成
- **GPU费用**：¥8.50/小时/张
- **CPU费用**：¥0.20/小时/核
- **网络费用**：跨区流量另计

### 省钱技巧
1. **按需使用**：及时释放闲置资源
2. **弹性调度**：低峰时段训练
3. **资源预留**：长期任务购买预留实例
4. **监控告警**：避免资源浪费

## 最佳实践

### ✅ 推荐做法
1. **同区域多可用区**：延迟低，效率高
2. **合理资源配比**：避免资源瓶颈
3. **实时监控**：及时发现问题
4. **定期保存检查点**：防止数据丢失
5. **测试后上线**：先小规模测试

### ❌ 避免事项
1. **避免过度跨区**：通信开销大
2. **避免资源不均**：负载不平衡
3. **避免忽视延迟**：影响训练效率
4. **避免单点依赖**：降低可用性
5. **避免资源浪费**：成本高昂

## 故障排查

### 常见问题

#### Q1: 跨可用区通信失败
**原因**：网络配置问题
**解决**：检查安全组配置，确保可用区间网络互通

#### Q2: 训练速度慢
**原因**：跨区通信延迟高
**解决**：
- 使用同区域可用区
- 开启梯度压缩
- 调整batch size

#### Q3: 资源分配不均
**原因**：各可用区配置不一致
**解决**：确保各可用区GPU/节点配置相同

#### Q4: 某个可用区故障
**原因**：机房网络或设备故障
**解决**：系统自动故障转移，或手动迁移到其他可用区

## 技术支持

遇到问题？
- 📧 邮箱：support@fermi-cluster.com
- 📞 电话：400-xxx-xxxx
- 💬 在线客服：工作日 9:00-18:00

## 更新日志

### v1.0.0 (2024-12-05)
- ✨ 初始版本发布
- ✨ 支持训练任务跨可用区调度
- ✨ 支持推理服务跨可用区部署
- ✨ 实时拓扑可视化
- ✨ 多维度监控指标
