# æ•°æ®é›†ä¸å­˜å‚¨å·å¿«é€Ÿä¸Šæ‰‹æŒ‡å—

## ğŸš€ 5åˆ†é’Ÿå¿«é€Ÿå¼€å§‹

### åœºæ™¯ 1ï¼šä»å­˜å‚¨å·åˆ›å»ºæ•°æ®é›†

**æˆ‘æœ‰æ•°æ®åœ¨å­˜å‚¨å·ä¸­ï¼Œæƒ³è¦æ³¨å†Œä¸ºå¹³å°æ•°æ®é›†**

```bash
1. æ‰“å¼€ï¼šæ•°æ®ç®¡ç† â†’ æ•°æ®é›†ç®¡ç†
2. ç‚¹å‡»ï¼šä»å­˜å‚¨å·åˆ›å»º
3. é€‰æ‹©ï¼šåŒ…å«æ•°æ®çš„å­˜å‚¨å·
4. æµè§ˆï¼šæ‰¾åˆ°æ•°æ®æ‰€åœ¨ç›®å½•
5. é…ç½®ï¼šå¡«å†™æ•°æ®é›†åç§°å’Œç±»å‹
6. å®Œæˆï¼šæ•°æ®é›†åˆ›å»ºæˆåŠŸ
```

**ç¤ºä¾‹**ï¼š
```
å­˜å‚¨å·ï¼šmy-storage (500GB)
ç›®å½•ï¼š/datasets/cifar10-processed
â†“
æ•°æ®é›†ï¼šCIFAR10-Processed (10GB, 6ä¸‡å¼ å›¾ç‰‡)
```

---

### åœºæ™¯ 2ï¼šåœ¨å¼€å‘ç¯å¢ƒä¸­ä½¿ç”¨æ•°æ®é›†

**æˆ‘æƒ³ç”¨å¹³å°æ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œå¹¶ä¿å­˜ç»“æœ**

```bash
1. æ‰“å¼€ï¼šè®¡ç®—èµ„æº â†’ å®ä¾‹ç®¡ç† â†’ åˆ›å»ºå®ä¾‹
2. é…ç½®ï¼šé€‰æ‹©é•œåƒã€GPUç­‰èµ„æº
3. åˆ‡æ¢åˆ°ï¼šå­˜å‚¨æŒ‚è½½ Tab
4. ç‚¹å‡»ï¼šæŒ‚è½½æ•°æ®é›†ï¼ˆé€‰æ‹©è®­ç»ƒç”¨æ•°æ®é›†ï¼‰
5. ç‚¹å‡»ï¼šæŒ‚è½½å­˜å‚¨å·ï¼ˆé€‰æ‹©ä¿å­˜ç»“æœçš„å·ï¼‰
6. å¯åŠ¨ï¼šå®ä¾‹åˆ›å»ºå®Œæˆ
```

**æŒ‚è½½é…ç½®ç¤ºä¾‹**ï¼š
```
æŒ‚è½½ç‚¹ #1 [æ•°æ®é›†]
â”œâ”€â”€ æ•°æ®æºï¼šImageNet-2024
â”œâ”€â”€ è·¯å¾„ï¼š/datasets/imagenet
â””â”€â”€ æƒé™ï¼šåªè¯» âœ“

æŒ‚è½½ç‚¹ #2 [å­˜å‚¨å·]
â”œâ”€â”€ æ•°æ®æºï¼šwork-volume
â”œâ”€â”€ è·¯å¾„ï¼š/workspace
â””â”€â”€ æƒé™ï¼šè¯»å†™ âœ“
```

**åœ¨å®¹å™¨ä¸­ä½¿ç”¨**ï¼š
```python
# è¯»å–æ•°æ®é›†ï¼ˆåªè¯»ï¼‰
train_data = ImageFolder('/datasets/imagenet/train')

# ä¿å­˜ç»“æœåˆ°å­˜å‚¨å·ï¼ˆè¯»å†™ï¼‰
torch.save(model.state_dict(), '/workspace/model.pth')
```

---

### åœºæ™¯ 3ï¼šæ•°æ®æ‰©å¢å·¥ä½œæµ

**æˆ‘æƒ³åŸºäºç°æœ‰æ•°æ®é›†åˆ›å»ºæ‰©å¢ç‰ˆæœ¬**

#### æ­¥éª¤ 1ï¼šåˆ›å»ºå¼€å‘ç¯å¢ƒ

```bash
å®ä¾‹é…ç½®ï¼š
- é•œåƒï¼šPyTorch 2.1.0
- æŒ‚è½½æ•°æ®é›†ï¼šImageNet-2024 â†’ /datasets/source (åªè¯»)
- æŒ‚è½½å­˜å‚¨å·ï¼šwork-volume â†’ /workspace (è¯»å†™)
```

#### æ­¥éª¤ 2ï¼šè¿è¡Œæ‰©å¢è„šæœ¬

```python
# augment.py
from torchvision import transforms
from PIL import Image
import os

# æºæ•°æ®ï¼ˆåªè¯»ï¼‰
src_dir = '/datasets/source/train'

# è¾“å‡ºç›®å½•ï¼ˆè¯»å†™ï¼‰
out_dir = '/workspace/augmented'
os.makedirs(out_dir, exist_ok=True)

# æ•°æ®æ‰©å¢
transform = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(15),
    transforms.ColorJitter(0.2, 0.2, 0.2),
])

for img_file in os.listdir(src_dir):
    img = Image.open(f'{src_dir}/{img_file}')
    aug_img = transform(img)
    aug_img.save(f'{out_dir}/aug_{img_file}')
    
print('æ•°æ®æ‰©å¢å®Œæˆï¼')
```

#### æ­¥éª¤ 3ï¼šæ³¨å†Œä¸ºæ–°æ•°æ®é›†

```bash
1. æ‰“å¼€ï¼šæ•°æ®é›†ç®¡ç† â†’ ä»å­˜å‚¨å·åˆ›å»º
2. é€‰æ‹©ï¼šwork-volume
3. ç›®å½•ï¼š/workspace/augmented
4. åç§°ï¼šImageNet-2024-Augmented
5. å®Œæˆï¼šæ–°æ•°æ®é›†åˆ›å»ºæˆåŠŸ
```

---

## ğŸ“‹ å¸¸ç”¨æ“ä½œé€ŸæŸ¥

### åˆ›å»ºæ•°æ®é›†çš„ä¸¤ç§æ–¹å¼

| æ–¹å¼ | é€‚ç”¨åœºæ™¯ | æ“ä½œä½ç½® | æ•°æ®æ¥æº |
|------|---------|---------|---------|
| ä¸Šä¼ æ–°æ•°æ®é›† | æœ¬åœ°æœ‰æ•°æ®æ–‡ä»¶ | æ•°æ®é›†ç®¡ç†é¡µ | æœ¬åœ°ä¸Šä¼  |
| ä»å­˜å‚¨å·åˆ›å»º | å­˜å‚¨å·ä¸­å·²æœ‰æ•°æ® | æ•°æ®é›†ç®¡ç†é¡µ | å­˜å‚¨å·ç›®å½• |

### æ•°æ®æŒ‚è½½çš„ä¸¤ç§ç±»å‹

| ç±»å‹ | æƒé™ | ç”¨é€” | æ“ä½œ |
|------|------|------|------|
| æ•°æ®é›†æŒ‚è½½ | åªè¯» | è®­ç»ƒã€éªŒè¯ | è¯»å–æ•°æ® |
| å­˜å‚¨å·æŒ‚è½½ | è¯»å†™ | å·¥ä½œç©ºé—´ | è¯»å†™æ–‡ä»¶ |

### æ¨èçš„ç›®å½•ç»“æ„

```
å­˜å‚¨å·ï¼šwork-volume
â”œâ”€â”€ raw/              # åŸå§‹æ•°æ®
â”œâ”€â”€ processed/        # å¤„ç†åçš„æ•°æ®
â”‚   â”œâ”€â”€ dataset-v1/   # å¯æ³¨å†Œä¸ºæ•°æ®é›†
â”‚   â””â”€â”€ dataset-v2/   # å¯æ³¨å†Œä¸ºæ•°æ®é›†
â”œâ”€â”€ experiments/      # å®éªŒæ•°æ®
â””â”€â”€ models/          # æ¨¡å‹è¾“å‡º
    â”œâ”€â”€ checkpoints/
    â””â”€â”€ final/
```

---

## ğŸ’¡ æœ€ä½³å®è·µ

### âœ… æ¨èåšæ³•

1. **æ•°æ®é›†åªè¯»**
   - æ•°æ®é›†æ°¸è¿œä¿æŒåªè¯»
   - éœ€è¦ä¿®æ”¹æ—¶åˆ›å»ºæ–°ç‰ˆæœ¬
   - ä¿è¯æ•°æ®å®Œæ•´æ€§

2. **å·¥ä½œæ•°æ®ç”¨å­˜å‚¨å·**
   - ä¸´æ—¶æ–‡ä»¶ã€å®éªŒæ•°æ®ç”¨å­˜å‚¨å·
   - è¯»å†™æ¨¡å¼æŒ‚è½½åˆ° /workspace
   - ä¾¿äºç®¡ç†å’Œæ¸…ç†

3. **è§„èŒƒå‘½å**
   - æ•°æ®é›†ï¼š`ProjectName-DataType-v1`
   - å­˜å‚¨å·ï¼š`username-workspace`
   - æŒ‚è½½è·¯å¾„ï¼š`/datasets/*` å’Œ `/workspace/*`

4. **ç‰ˆæœ¬ç®¡ç†**
   - é‡è¦çš„æ•°æ®å¤„ç†ç»“æœæ³¨å†Œä¸ºæ•°æ®é›†
   - ä½¿ç”¨è¯­ä¹‰åŒ–ç‰ˆæœ¬å·
   - æ·»åŠ è¯¦ç»†æè¿°ä¿¡æ¯

### âŒ é¿å…çš„åšæ³•

1. **ä¸è¦**åœ¨æ•°æ®é›†æŒ‚è½½ç‚¹å†™å…¥
   - ç³»ç»Ÿä¼šé˜»æ­¢ï¼ˆåªè¯»æ¨¡å¼ï¼‰

2. **ä¸è¦**æ··ç”¨æ•°æ®é›†å’Œå­˜å‚¨å·
   - æ•°æ®é›†ç”¨äºæ ‡å‡†åŒ–çš„è®­ç»ƒæ•°æ®
   - å­˜å‚¨å·ç”¨äºå·¥ä½œæ–‡ä»¶

3. **ä¸è¦**ä½¿ç”¨ç›¸åŒçš„æŒ‚è½½è·¯å¾„
   - æ¯ä¸ªæŒ‚è½½ç‚¹å¿…é¡»æœ‰å”¯ä¸€è·¯å¾„

---

## ğŸ¯ å…¸å‹åº”ç”¨åœºæ™¯

### 1. å›¾åƒåˆ†ç±»æ•°æ®æ‰©å¢

```python
# åœºæ™¯ï¼šåŸºäº ImageNet åˆ›å»º 3 å€æ‰©å¢æ•°æ®é›†
# æŒ‚è½½ï¼š/datasets/imagenet (åªè¯») + /workspace (è¯»å†™)

import albumentations as A
from PIL import Image

aug = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.RandomRotate90(p=0.5),
    A.RandomBrightnessContrast(p=0.5),
])

for img_path in dataset:
    img = Image.open(f'/datasets/imagenet/{img_path}')
    for i in range(3):
        augmented = aug(image=img)
        augmented.save(f'/workspace/augmented/{i}_{img_path}')

# å®Œæˆåï¼šä» /workspace/augmented åˆ›å»ºæ–°æ•°æ®é›†
```

### 2. æ–‡æœ¬æ•°æ®æ¸…æ´—

```python
# åœºæ™¯ï¼šæ¸…æ´—è¯­æ–™åº“ï¼Œå»é™¤é‡å¤å’Œä½è´¨é‡æ–‡æœ¬
# æŒ‚è½½ï¼š/datasets/corpus (åªè¯») + /workspace (è¯»å†™)

import pandas as pd

# è¯»å–åŸå§‹æ•°æ®
df = pd.read_csv('/datasets/corpus/raw_text.csv')

# æ¸…æ´—
df = df.drop_duplicates()
df = df[df['text'].str.len() > 50]
df = df[df['quality_score'] > 0.7]

# ä¿å­˜
df.to_csv('/workspace/cleaned/text.csv')

# å®Œæˆåï¼šä» /workspace/cleaned åˆ›å»ºæ–°æ•°æ®é›†
```

### 3. å¤šæ•°æ®é›†æ··åˆ

```python
# åœºæ™¯ï¼šæ··åˆå¤šä¸ªæ•°æ®é›†åˆ›å»ºè”åˆæ•°æ®é›†
# æŒ‚è½½ï¼š/datasets/ds1 (åªè¯») + /datasets/ds2 (åªè¯») + /workspace (è¯»å†™)

import shutil
import os

# åˆ›å»ºæ··åˆæ•°æ®é›†ç›®å½•
output_dir = '/workspace/mixed-dataset'
os.makedirs(output_dir, exist_ok=True)

# å¤åˆ¶å¹¶é‡å‘½å
for f in os.listdir('/datasets/ds1'):
    shutil.copy(f'/datasets/ds1/{f}', f'{output_dir}/ds1_{f}')
    
for f in os.listdir('/datasets/ds2'):
    shutil.copy(f'/datasets/ds2/{f}', f'{output_dir}/ds2_{f}')

# å®Œæˆåï¼šä» /workspace/mixed-dataset åˆ›å»ºæ–°æ•°æ®é›†
```

---

## ğŸ”§ æ•…éšœæ’æŸ¥

### é—®é¢˜ï¼šæŒ‚è½½ç‚¹æ˜¾ç¤ºä¸ºç©º

**åŸå› **ï¼šç›®å½•ä¸å­˜åœ¨æˆ–è·¯å¾„é”™è¯¯

**è§£å†³**ï¼š
```bash
# åœ¨å®¹å™¨ä¸­æ£€æŸ¥
ls -la /datasets/
ls -la /workspace/

# ç¡®è®¤æŒ‚è½½æ˜¯å¦æˆåŠŸ
mount | grep datasets
```

### é—®é¢˜ï¼šæ— æ³•å†™å…¥æ•°æ®é›†ç›®å½•

**åŸå› **ï¼šæ•°æ®é›†æŒ‚è½½ä¸ºåªè¯»

**è§£å†³**ï¼š
- æ•°æ®é›†æœ¬å°±åº”è¯¥åªè¯»
- éœ€è¦å†™å…¥è¯·ä½¿ç”¨å­˜å‚¨å·æŒ‚è½½
- æ£€æŸ¥æŒ‚è½½ç±»å‹å’Œæƒé™

### é—®é¢˜ï¼šå­˜å‚¨ç©ºé—´ä¸è¶³

**åŸå› **ï¼šå­˜å‚¨å·å®¹é‡å·²æ»¡

**è§£å†³**ï¼š
```bash
# æ£€æŸ¥ä½¿ç”¨æƒ…å†µ
df -h /workspace

# æ¸…ç†ä¸éœ€è¦çš„æ–‡ä»¶
rm -rf /workspace/temp/*

# æˆ–æ‰©å®¹å­˜å‚¨å·ï¼ˆåœ¨å­˜å‚¨ç®¡ç†é¡µé¢ï¼‰
```

### é—®é¢˜ï¼šæ‰¾ä¸åˆ°æ•°æ®é›†æ–‡ä»¶

**åŸå› **ï¼šè·¯å¾„é…ç½®é”™è¯¯æˆ–æ–‡ä»¶ä¸åœ¨é¢„æœŸä½ç½®

**è§£å†³**ï¼š
```bash
# æ£€æŸ¥å®é™…æŒ‚è½½è·¯å¾„
mount | grep datasets

# æŸ¥çœ‹ç›®å½•å†…å®¹
find /datasets -name "*.jpg" | head

# æ£€æŸ¥æ–‡ä»¶æƒé™
ls -l /datasets/
```

---

## ğŸ“ è·å–å¸®åŠ©

**æ–‡æ¡£èµ„æº**ï¼š
- å®Œæ•´å·¥ä½œæµè¯´æ˜ï¼š`DATASET_VOLUME_WORKFLOW.md`
- å¹³å°æ–‡æ¡£ï¼š[https://docs.fermi.com](https://docs.fermi.com)

**æ”¯æŒæ¸ é“**ï¼š
- æŠ€æœ¯æ”¯æŒé‚®ç®±ï¼šsupport@fermi.com
- å¹³å°å†…å·¥å•ç³»ç»Ÿ
- ç”¨æˆ·ç¤¾åŒºè®ºå›

**å¸¸è§é—®é¢˜**ï¼š
- FAQï¼š[https://docs.fermi.com/faq](https://docs.fermi.com/faq)
- è§†é¢‘æ•™ç¨‹ï¼š[https://docs.fermi.com/videos](https://docs.fermi.com/videos)

---

## âš¡ å¿«é€Ÿå‘½ä»¤å¤‡å¿˜

```bash
# æ£€æŸ¥æŒ‚è½½
mount | grep -E "datasets|workspace"

# æŸ¥çœ‹æ•°æ®é›†
ls -lh /datasets/

# æŸ¥çœ‹å·¥ä½œç©ºé—´
ls -lh /workspace/

# æ£€æŸ¥ç£ç›˜ä½¿ç”¨
df -h

# æ•°æ®å¤„ç†ç¤ºä¾‹ï¼ˆPythonï¼‰
python3 << 'EOF'
import os
print("æ•°æ®é›†æŒ‚è½½ç‚¹:", os.listdir('/datasets'))
print("å·¥ä½œç©ºé—´:", os.listdir('/workspace'))
EOF

# å‹ç¼©ç»“æœ
cd /workspace
tar -czf processed-data.tar.gz processed/

# æŸ¥çœ‹æ–‡ä»¶æ•°é‡
find /datasets -type f | wc -l
find /workspace -type f | wc -l
```

---

**æ›´æ–°æ—¥æœŸ**ï¼š2024-11-14  
**ç‰ˆæœ¬**ï¼šv1.0
