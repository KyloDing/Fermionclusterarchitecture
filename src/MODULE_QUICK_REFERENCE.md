# AI工作负载模块快速参考

## 🎯 5秒决策指南

```
我想做什么？                          → 应该用哪个模块？
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
用Jupyter写代码/分析数据              → 开发环境 🖥️
调试训练脚本                          → 开发环境 🖥️
跑个小实验看看效果                    → 开发环境 🖥️
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
训练一个大模型                        → 训练任务 ⚡
做超参数调优                          → 训练任务 ⚡
跑分布式训练                          → 训练任务 ⚡
定时重训练模型                        → 训练任务 ⚡
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
给App提供AI接口                      → 推理服务 🚀
部署生产环境API                       → 推理服务 🚀
需要高并发推理                        → 推理服务 🚀
模型需要自动扩容                      → 推理服务 🚀
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
需要特殊的Python库                    → 镜像管理 📦
想自己构建运行环境                    → 镜像管理 📦
需要特定版本的CUDA                    → 镜像管理 📦
```

---

## 🔍 详细对比表

| 维度 | 🖥️ 开发环境 | ⚡ 训练任务 | 🚀 推理服务 |
|------|------------|-----------|-----------|
| **运行模式** | 长期运行 | 任务执行完自动结束 | 持续运行 |
| **交互方式** | 可登录终端/Jupyter | 提交后自动执行 | API调用 |
| **生命周期** | 手动启停 | 自动管理 | 自动管理 |
| **资源调度** | 立即分配 | 排队调度 | 自动扩缩容 |
| **使用时长** | 按需使用 | 几小时到几天 | 7x24运行 |
| **典型GPU数** | 1-2卡 | 4-64卡 | 1-4卡/副本 |
| **费用模式** | 按运行时长 | 按任务时长 | 按副本*时长 |
| **适合人群** | 开发者 | 算法工程师 | 应用开发者 |

---

## 📋 功能清单对比

### 开发环境 ✅ / ❌

| 功能 | 支持 |
|------|------|
| Jupyter Notebook | ✅ |
| SSH终端登录 | ✅ |
| 实时代码调试 | ✅ |
| 安装自定义软件 | ✅ |
| 可视化工具（如TensorBoard） | ✅ |
| 分布式训练 | ❌ |
| 自动排队调度 | ❌ |
| 实验追踪 | ❌ |
| 自动扩缩容 | ❌ |
| 负载均衡 | ❌ |

### 训练任务 ✅ / ❌

| 功能 | 支持 |
|------|------|
| 分布式多机训练 | ✅ |
| 自动排队调度 | ✅ |
| 实验追踪管理 | ✅ |
| 断点续传 | ✅ |
| 超参数管理 | ✅ |
| 自动保存模型 | ✅ |
| 实时交互式操作 | ❌ |
| 手动安装软件 | ❌ |
| 对外提供服务 | ❌ |

### 推理服务 ✅ / ❌

| 功能 | 支持 |
|------|------|
| REST API接口 | ✅ |
| 多副本部署 | ✅ |
| 自动扩缩容 | ✅ |
| 负载均衡 | ✅ |
| 健康检查 | ✅ |
| 灰度发布 | ✅ |
| 版本管理 | ✅ |
| 交互式开发 | ❌ |
| 训练模型 | ❌ |

---

## 🎬 典型使用场景

### 开发环境 🖥️

```
场景1: 数据科学家的日常工作
├─ 早上：启动Jupyter实例
├─ 上午：探索性数据分析
├─ 下午：特征工程实验
├─ 晚上：停止实例
└─ 费用：约 ¥50/天 (8小时 * 2卡A100)

场景2: 算法工程师调试代码
├─ 创建开发实例
├─ SSH登录，修改代码
├─ 小批量数据测试
├─ 确认无误后提交训练任务
└─ 删除开发实例

场景3: 运行可视化工具
├─ 创建实例，暴露6006端口
├─ 运行TensorBoard
├─ 在浏览器查看训练曲线
└─ 分析完成后停止
```

### 训练任务 ⚡

```
场景1: 大语言模型预训练
├─ 配置：64机512卡A100
├─ 数据：1TB预训练语料
├─ 时长：7天
├─ 费用：约 ¥500,000
└─ 产出：预训练基座模型

场景2: 视觉模型微调
├─ 配置：单机8卡V100
├─ 数据：10万张图片
├─ 时长：12小时
├─ 费用：约 ¥960
└─ 产出：微调后模型

场景3: 超参数网格搜索
├─ 提交：100个不同超参数组合
├─ 自动排队执行
├─ 对比实验结果
└─ 选择最优配置
```

### 推理服务 🚀

```
场景1: 聊天机器人API
├─ 模型：GPT-3.5
├─ 配置：2-10副本自动扩容
├─ QPS：100-1000
├─ 延迟：< 500ms
└─ 费用：约 ¥500/天

场景2: 图像识别服务
├─ 模型：ResNet-50
├─ 配置：固定3副本
├─ QPS：5000
├─ 延迟：< 50ms
└─ 费用：约 ¥300/天

场景3: 灰度发布新版本
├─ 旧版本：90%流量
├─ 新版本：10%流量
├─ 监控指标对比
├─ 逐步切换到100%
└─ 平滑升级无感知
```

---

## ⏱️ 生命周期对比

### 开发环境
```
创建 → 运行中 ←→ 停止 → 删除
       ↑__________|
       (随时启停)
```

### 训练任务
```
提交 → 排队 → 运行中 → 完成/失败 (自动清理资源)
                ↓
            可手动停止
```

### 推理服务
```
部署 → 运行中 ←→ 更新版本 → 下线
       ↑_______|
       (自动扩缩容)
```

---

## 💰 费用对比示例

假设使用单卡A100 (¥10/小时)

| 使用场景 | 模块 | 配置 | 时长 | 费用 |
|---------|------|------|------|------|
| 数据分析 | 开发环境 | 1卡 | 8小时/天 | ¥80/天 |
| 代码调试 | 开发环境 | 1卡 | 2小时 | ¥20 |
| 模型训练 | 训练任务 | 8卡 | 12小时 | ¥960 |
| API服务（低流量） | 推理服务 | 1卡×1副本 | 24小时 | ¥240/天 |
| API服务（高流量） | 推理服务 | 2卡×5副本 | 24小时 | ¥2400/天 |

**省钱技巧**：
- 开发环境：用完就停，不要24小时运行
- 训练任务：合理配置资源，避免过度分配
- 推理服务：配置自动扩缩容，低峰期自动减少副本

---

## 🔄 模块间协作

### 完整AI项目流程

```
1️⃣ 镜像管理
   选择/创建合适的Docker镜像
   ↓
2️⃣ 开发环境
   Jupyter开发 → 数据探索 → 代码调试
   ↓
3️⃣ 训练任务
   提交训练 → 自动执行 → 保存模型
   ↓
4️⃣ 开发环境
   加载模型 → 评估测试 → 优化
   ↓
5️⃣ 推理服务
   部署API → 生产运行 → 监控
   ↓
   (循环迭代)
```

---

## ❓ 常见问题

### Q1: 我可以在开发环境里跑训练吗？
**A**: 可以，但不推荐。小规模测试可以，大规模训练请用"训练任务"模块，它有：
- ✅ 自动排队调度
- ✅ 实验追踪
- ✅ 断点续传
- ✅ 资源自动释放

### Q2: 训练任务可以登录看日志吗？
**A**: 可以实时查看日志，但无法登录交互式操作。如需调试，请先在"开发环境"中测试。

### Q3: 推理服务能用来做实验吗？
**A**: 不建议。推理服务是面向生产的，如需实验请用"开发环境"或"训练任务"。

### Q4: 如何选择合适的镜像？
**A**: 
1. 优先使用"镜像管理"中的官方镜像
2. 需要特殊环境可创建自定义镜像
3. 不同模块可使用不同镜像（开发、训练、推理）

### Q5: 三个模块可以同时用吗？
**A**: 当然可以！典型流程是：
- 开发环境：写代码、调试
- 训练任务：正式训练
- 推理服务：部署上线

---

## 📌 快速操作指南

### 创建开发环境（3步）
```
1. 点击"AI工作负载 → 开发环境"
2. 点击"创建实例"
3. 选择镜像 → 配置资源 → 创建
```

### 提交训练任务（4步）
```
1. 点击"AI工作负载 → 训练任务"
2. 点击"创建训练任务"
3. 配置代码仓库和启动命令
4. 选择镜像 → 配置资源 → 提交
```

### 部署推理服务（3步）
```
1. 点击"AI工作负载 → 推理服务"
2. 点击"部署推理服务"
3. 选择模型 → 配置资源 → 部署
```

---

## 🎓 学习路径建议

### 初学者
```
第1周：熟悉"开发环境"
├─ 创建Jupyter实例
├─ 运行示例代码
└─ 练习启动和停止

第2周：尝试"镜像管理"
├─ 浏览官方镜像
├─ 理解镜像规格
└─ 选择合适镜像

第3周：使用"训练任务"
├─ 提交简单训练任务
├─ 监控训练进度
└─ 查看训练结果

第4周：部署"推理服务"
├─ 部署已训练模型
├─ 调用API接口
└─ 监控服务状态
```

### 进阶用户
```
1. 创建自定义镜像
2. 配置分布式训练
3. 实现CI/CD自动化
4. 优化推理性能
5. 成本优化策略
```

---

**快速帮助**：查看各页面顶部的彩色说明卡片 💡
**详细文档**：参考 `AI_WORKLOAD_GUIDE.md` 📚
